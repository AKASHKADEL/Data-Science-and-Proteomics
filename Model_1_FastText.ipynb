{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "from Bio import SeqIO\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "def load_test_sets(filename):\n",
    "    go_data = sio.loadmat(filename, squeeze_me=True)\n",
    "    go_terms = go_data['goTerm_labels'] # names of gene ontology function terms\n",
    "    train_annotations = np.asarray(go_data['trainProts_label'].todense()) # training set of function annotations\n",
    "    valid_annotations = np.asarray(go_data['validProts_label'].todense()) # valid \"\" \"\"\n",
    "    test_annotations = np.asarray(go_data['testProts_label'].todense()) # test \"\" \"\"\n",
    "    train_inds = go_data['trainProts']\n",
    "    train_inds = train_inds - 1\n",
    "    valid_inds = go_data['validProts']\n",
    "    valid_inds = valid_inds - 1\n",
    "    test_inds = go_data['testProts']\n",
    "    test_inds = test_inds - 1 # subtract 1 for matlab index conversion into python\n",
    "\n",
    "    return train_inds, valid_inds, test_inds, train_annotations, valid_annotations, test_annotations, go_terms\n",
    "\n",
    "def load_FASTA(filename):\n",
    "    \"\"\" Loads fasta file and returns a list of the Bio SeqIO records \"\"\"\n",
    "    infile = open(filename)\n",
    "    full_entries = list(SeqIO.parse(infile, 'fasta'))\n",
    "    sequences = [str(entry.seq) for entry in full_entries]\n",
    "    names = [str(entry.id) for entry in full_entries]\n",
    "\n",
    "    return sequences, names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load human sequences and create train/dev/test sets, create lengths for FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "human_sequences, human_protein_names = load_FASTA('../data/human_sequences.fasta')\n",
    "human_train_idx, human_valid_idx, human_test_idx, human_train_labels, human_valid_labels, \\\n",
    "    human_test_labels, human_GO_terms = load_test_sets('../data/human_annotations_temporal_holdout.mat')\n",
    "\n",
    "# Create train, validation, and test sets from the full list of human proteins\n",
    "human_train_sequences = [human_sequences[i] for i in human_train_idx]\n",
    "human_valid_sequences = [human_sequences[i] for i in human_valid_idx]\n",
    "human_test_sequences = [human_sequences[i] for i in human_test_idx]\n",
    "\n",
    "# Convert corresponding labels for train, validation, and test sets from the full list of human proteins.\n",
    "human_train_labels = torch.from_numpy(human_train_labels).type(torch.LongTensor)\n",
    "human_valid_labels = torch.from_numpy(human_valid_labels).type(torch.LongTensor)\n",
    "human_test_labels = torch.from_numpy(human_test_labels).type(torch.LongTensor)\n",
    "\n",
    "# Create lengths for sequence representation averaging in FastText\n",
    "human_train_lengths = torch.LongTensor([len(human_train_sequences[i]) for i in range(len(human_train_sequences))])\n",
    "human_valid_lengths = torch.LongTensor([len(human_valid_sequences[i]) for i in range(len(human_valid_sequences))])\n",
    "human_test_lengths = torch.LongTensor([len(human_test_sequences[i]) for i in range(len(human_test_sequences))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load yeast sequences and create train/dev/test sets, create lengths for FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load yeast sequences and training data\n",
    "yeast_sequences, yeast_protein_names = load_FASTA('../data/yeast_sequences.fasta')\n",
    "yeast_train_idx, yeast_valid_idx, yeast_test_idx, yeast_train_labels, yeast_valid_labels, \\\n",
    "    yeast_test_labels, yeast_GO_terms = load_test_sets('../data/yeast_MF_temporal_holdout.mat')\n",
    "\n",
    "# Create train, validation, and test sets from the full list of yeast proteins\n",
    "yeast_train_sequences = [yeast_sequences[i] for i in yeast_train_idx]\n",
    "yeast_valid_sequences = [yeast_sequences[i] for i in yeast_valid_idx]\n",
    "yeast_test_sequences = [yeast_sequences[i] for i in yeast_test_idx]\n",
    "\n",
    "# Convert corresponding labels for train, validation, and test sets from the full list of yeast proteins.\n",
    "yeast_train_labels = torch.from_numpy(yeast_train_labels).type(torch.LongTensor)\n",
    "yeast_valid_labels = torch.from_numpy(yeast_valid_labels).type(torch.LongTensor)\n",
    "yeast_test_labels = torch.from_numpy(yeast_test_labels).type(torch.LongTensor)\n",
    "\n",
    "# Create lengths for sequence representation averaging in FastText\n",
    "yeast_train_lengths = torch.LongTensor([len(yeast_train_sequences[i]) for i in range(len(yeast_train_sequences))])\n",
    "yeast_valid_lengths = torch.LongTensor([len(yeast_valid_sequences[i]) for i in range(len(yeast_valid_sequences))])\n",
    "yeast_test_lengths = torch.LongTensor([len(yeast_test_sequences[i]) for i in range(len(yeast_test_sequences))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embed amino-acid chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Each amino-acid string becomes an NxD entry in a tensor, where N is the number of \n",
    "# amino-acid strings and D is the length of the longest chain in the set. \n",
    "\n",
    "ConvertCharToInt = {'A':1, 'B':2, 'C':3, 'D':4, 'E':5, 'F':6, 'G':7, 'H':8, 'I':9, 'J':10,\n",
    "                   'K':11, 'L':12, 'M':13, 'N':14, 'O':15, 'P':16, 'Q':17, 'R':18, 'S':19,\n",
    "                   'T':20, 'U':21, 'V':22, 'W':23, 'X':24, 'Y':25, 'Z':26}\n",
    "\n",
    "def vectorize_AAs(string):\n",
    "    '''This function takes an amino-acid string as input and outputs a vector of integers, with each\n",
    "    integer representing one amino acid.\n",
    "    \n",
    "    For example, 'BACEA' is converted to [2, 1, 3, 5, 1]\n",
    "    '''\n",
    "    character_list = list(string) #converts 'BACEA' to ['B','A','C','E','A]\n",
    "    for i in range(len(character_list)):\n",
    "        character_list[i] = ConvertCharToInt[character_list[i]] #convert the character to a number\n",
    "    return character_list\n",
    "\n",
    "def AddZeros(vector, max_length):\n",
    "    '''This function adds the necessary number of zeros and returns an array'''\n",
    "    #max_length = length of longest vector in the batch\n",
    "    #oldvector = initial vector for that amino-acid chain (in integers)\n",
    "    diff = max_length - len(vector)\n",
    "    if diff>0:\n",
    "        ZerosToAdd = np.zeros(diff)\n",
    "        vector.extend(ZerosToAdd)\n",
    "    return vector \n",
    "\n",
    "def TransformAAsToTensor(ListOfSequences):\n",
    "    '''This function takes as input a list of amino acid strings and creates a tensor matrix\n",
    "    of dimension NxD, where N is the number of strings and D is the length of the longest AA chain\n",
    "    \n",
    "    \"ListOfSequences\" can be training, validation, or test sets\n",
    "    '''\n",
    "    #find longest amino-acid sequence\n",
    "    max_length = len(max(ListOfSequences, key=len))\n",
    "    Sequences = ListOfSequences.copy() \n",
    "    for AA in range(len(Sequences)): #for each amino-acid sequence\n",
    "        Sequences[AA] = vectorize_AAs(Sequences[AA])\n",
    "        Sequences[AA] = AddZeros(Sequences[AA], max_length)\n",
    "    NewTensor = torch.from_numpy(np.array(Sequences))\n",
    "    return NewTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "human_train_vectors = TransformAAsToTensor(human_train_sequences)\n",
    "human_valid_vectors = TransformAAsToTensor(human_valid_sequences)\n",
    "human_test_vectors = TransformAAsToTensor(human_test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yeast_train_vectors = TransformAAsToTensor(yeast_train_sequences)\n",
    "yeast_valid_vectors = TransformAAsToTensor(yeast_valid_sequences)\n",
    "yeast_test_vectors = TransformAAsToTensor(yeast_test_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) Hyperparameter setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Get batch data method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def batch_iter(TrainSeqs, yTrain, TrainSeqsLength, batch_size):\n",
    "    start = -1 * batch_size\n",
    "    dataset_size = TrainSeqs.size()[0]\n",
    "    order = list(range(dataset_size))\n",
    "    random.shuffle(order)\n",
    "\n",
    "    while True:\n",
    "        start += batch_size\n",
    "        if start > dataset_size - batch_size:\n",
    "            # Start another epoch.\n",
    "            start = 0\n",
    "            random.shuffle(order)\n",
    "        batch_indices = order[start:start + batch_size]\n",
    "        batch_indices_tensor = torch.LongTensor(batch_indices)\n",
    "        batch_train = TrainSeqs[batch_indices_tensor].type(torch.LongTensor)\n",
    "        batch_train_labels = yTrain[batch_indices_tensor]\n",
    "        length_batch = TrainSeqsLength[batch_indices_tensor]\n",
    "        yield [Variable(batch_train), Variable(batch_train_labels), Variable(length_batch)]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) FastText class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FastText(nn.Module):\n",
    "    \"\"\"\n",
    "    FastText model\n",
    "    \"\"\"\n",
    "       \n",
    "    def __init__(self, vocab_size, emb_dim, num_labels):\n",
    "        \"\"\"\n",
    "        @param vocab_size: size of the vocabulary. \n",
    "        @param emb_dim: size of the word embedding\n",
    "        \"\"\"\n",
    "        super(FastText, self).__init__()\n",
    "\n",
    "        self.num_labels = num_labels\n",
    "        self.embed = nn.Embedding(vocab_size+1, emb_dim, padding_idx=0)\n",
    "        self.linear = nn.Linear(emb_dim,num_labels)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self, data, length):\n",
    "        \"\"\"\n",
    "        @param data: matrix of size (batch_size, max_sentence_length). Each row in data represents a \n",
    "            review that is represented using n-gram index. Note that they are padded to have same length.\n",
    "        @param length: an int tensor of size (batch_size), which represents the non-trivial (excludes padding)\n",
    "            length of each sentences in the data.\n",
    "        \"\"\"\n",
    "        data = data.type(torch.LongTensor)\n",
    "        out = self.embed(data)\n",
    "        out = torch.sum(out, dim=1)\n",
    "        out = out / length.view(-1,1).float()\n",
    "            \n",
    "        out = self.linear(out)\n",
    "        return nn.functional.sigmoid(out)\n",
    "    \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        lin_layers = [self.linear]\n",
    "        em_layer = [self.embed]\n",
    "     \n",
    "        for layer in lin_layers+em_layer:\n",
    "            layer.weight.data.uniform_(-initrange, initrange)\n",
    "            if layer in lin_layers:\n",
    "                layer.bias.data.fill_(0)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2B) LSTM class:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM model\n",
    "    \"\"\"  \n",
    "    def __init__(self, vocab_size, emb_dim, hidden_size, num_labels, batch_size):\n",
    "        \"\"\"\n",
    "        @param vocab_size: size of the vocabulary. \n",
    "        @param emb_dim: size of the word embedding\n",
    "        \"\"\"\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.emb_dim = emb_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.linear_f = nn.Linear(emb_dim + hidden_size, hidden_size)\n",
    "        self.linear_i = nn.Linear(emb_dim + hidden_size, hidden_size)\n",
    "        self.linear_ctilde = nn.Linear(emb_dim + hidden_size, hidden_size)\n",
    "        self.linear_o = nn.Linear(emb_dim + hidden_size, hidden_size)\n",
    "    \n",
    "        self.decoder = nn.Linear(hidden_size, num_labels)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self, data, hidden, c):\n",
    "        \"\"\"\n",
    "        @param data: matrix of size (batch_size, max_sentence_length). Each row in data represents a \n",
    "            review that is represented using n-gram index. Note that they are padded to have same length.\n",
    "        @param length: an int tensor of size (batch_size), which represents the non-trivial (excludes padding)\n",
    "            length of each sentences in the data.\n",
    "        \"\"\"\n",
    "        data = data.type(torch.LongTensor)\n",
    "        emb = self.embed(data)\n",
    "        embs = torch.chunk(emb, emb.size()[1], 1)\n",
    "        \n",
    "        def step(emb, hid, c_t):\n",
    "            combined = torch.cat((hid,emb),1)\n",
    "            f = F.sigmoid(self.linear_f(combined))\n",
    "            i = F.sigmoid(self.linear_i(combined))\n",
    "            c_tilde = F.tanh(self.linear_ctilde(combined))\n",
    "            c_t = f*c_t + i*c_tilde\n",
    "            o = F.sigmoid(self.linear_o(combined))\n",
    "            hid = o * F.tanh(c_t)\n",
    "            return hid, c_t\n",
    "        \n",
    "        for i in range(len(embs)):\n",
    "            hidden, c = step(embs[i].squeeze(), hidden, c)\n",
    "        output = self.decoder(hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        h0 = Variable(torch.zeros(self.batch_size, self.hidden_size))\n",
    "        c0 = Variable(torch.zeros(self.batch_size, self.hidden_size))\n",
    "        return h0, c0\n",
    "        \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        lin_layers = [self.linear_f, self.linear_i, self.linear_ctilde, self.linear_o]\n",
    "        em_layer = [self.embed]\n",
    "     \n",
    "        for layer in lin_layers+em_layer:\n",
    "            layer.weight.data.uniform_(-initrange, initrange)\n",
    "            if layer in lin_layers:\n",
    "                layer.bias.data.fill_(0)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,average_precision_score\n",
    "\n",
    "def round_manual(data, threshold):\n",
    "    return (data >= threshold).astype(int)\n",
    "\n",
    "def calculate_accuracy(predicted, actuals, num_labels):\n",
    "    \"\"\"\n",
    "    @param predicted: data type = Variable\n",
    "    @param actuals: data type = Variable\n",
    "    @param num_labels: no of go terms\n",
    "    @return: accuracy measure\n",
    "    \"\"\"\n",
    "    predicted = np.round(predicted.data.numpy())\n",
    "    total_predictions = actuals.size()[0]\n",
    "    accuracy = np.sum(predicted==actuals.data.numpy())/(total_predictions*num_labels)\n",
    "    return accuracy\n",
    "\n",
    "def m_tau(predictions):\n",
    "    return len([np.sum(i) for i in predictions if np.sum(i)!=0])\n",
    "\n",
    "def n_e(predictions):\n",
    "    return predictions.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "def calculate_recall_precision(predicted, actual):\n",
    "    '''\n",
    "    Overall, this function calculates the recall and precision of the validation set proteins.\n",
    "    The function FIRST calculates the precision and recall values of INDIVIDUAL proteins. \n",
    "    It then takes the mean average of these values to get \"dataset-level\" precision and recall.\n",
    "    '''\n",
    "    \n",
    "    PositivesPerRow = actual.numpy().sum(axis=1) #number of functions for each protein\n",
    "    PosPredictionsPerRow = predicted.sum(axis=1) #number of predictions for each protein\n",
    "    TPs = np.multiply(actual.numpy(), predicted) #element-wise multiplication: 1 if TP, else 0\n",
    "    TPsPerRow = TPs.sum(axis=1) #number of true positives for each protein\n",
    "    \n",
    "    #PrecisionPerRow (Protein) - if protein has 0 positive predictions, the protein's precision = 0.\n",
    "    #Else, the protein's precision = TPs/PositivePreds\n",
    "    PrecisionPerRow = np.where(PosPredictionsPerRow == 0, 0, TPsPerRow/PosPredictionsPerRow)\n",
    "    RecallPerRow = np.where(PositivesPerRow==0, 0, TPsPerRow/PositivesPerRow) #Recall per Protein\n",
    "    \n",
    "    #RecallScore = average of individual protein recall scores\n",
    "    RecallScore = sum(RecallPerRow)/len(RecallPerRow) #denominator is non-zero\n",
    "    \n",
    "    #PrecisionScore = average of CERTAIN individual protein precision scores (see line below)\n",
    "    #Only consider rows with at least one predicted Go-Term.\n",
    "    #Note that some proteins can have Precision=0 but still have predictions.\n",
    "    if sum(PrecisionPerRow)>0:\n",
    "        PrecisionScore = sum(PrecisionPerRow)/len([x for x in PosPredictionsPerRow if x!=0]) \n",
    "    else:\n",
    "        PrecisionScore = 0\n",
    "    return RecallScore, PrecisionScore\n",
    "    \n",
    "    \n",
    "def F_score(predicted, actuals):\n",
    "    \"\"\"\n",
    "    @param predicted: data type = Variable\n",
    "    @param actuals: data type = Variable\n",
    "    @return: Maximum f score over all values of tau and the corresponding tau threshold\n",
    "    \"\"\"\n",
    "    f_max, optimal_threshold, optimal_precision, optimal_recall = 0, 0, 0, 0\n",
    "    for threshold in [i/100 for i in range(1,100)]:\n",
    "        predicted_tau = round_manual(predicted.data.numpy(), threshold)\n",
    "        recall_score, precision_score = calculate_recall_precision(predicted_tau, actuals)\n",
    "        \n",
    "        if recall_score==0 and precision_score==0:\n",
    "            output = 0\n",
    "        else:\n",
    "            output = ((2*precision_score*recall_score) / (precision_score + recall_score))\n",
    "        if output > f_max:\n",
    "            f_max = output\n",
    "            optimal_threshold = threshold\n",
    "            optimal_precision = precision_score\n",
    "            optimal_recall = recall_score\n",
    "    \n",
    "    return f_max, optimal_threshold, optimal_precision, optimal_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Early stop condition and training stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def early_stop(val_acc_history, t=10, required_progress=0.001):\n",
    "    \"\"\"\n",
    "    Stop the training if there is no non-trivial progress in k steps\n",
    "    @param val_acc_history: a list contains all the historical validation acc\n",
    "    @param required_progress: the next acc should be higher than the previous by \n",
    "        at least required_progress amount to be non-trivial\n",
    "    @param t: number of training steps \n",
    "    @return: a boolean indicates if the model should earily stop\n",
    "    \"\"\"\n",
    "    # TODO: add your code here\n",
    "    \n",
    "    cnt = 0 # initialize the count --> to store count of cases where difference in\n",
    "                                    #  accuracy is less than required progress.\n",
    "    \n",
    "    if(len(val_acc_history) > 0): # if list has size > 0 \n",
    "        for i in range(t): # start the loop\n",
    "            index = len(val_acc_history) - (i+1) # start from the last term in list and move to the left\n",
    "            if (index >= 1): # to check if index != 0 --> else we can't compare to previous value\n",
    "                if ((val_acc_history[index] - val_acc_history[index-1]) < required_progress):\n",
    "                    cnt += 1 # increase the count value\n",
    "                else:\n",
    "                    break # break if difference is greater \n",
    "    \n",
    "    if(cnt != t): # if count is equal to t, return True\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "    \n",
    "def train_test(valid_sequences, valid_label, valid_length, num_epochs, optimizer, data_iter, model, training_length, lstm=False):\n",
    "    losses = []\n",
    "    total_batches = int(training_length/ batch_size)\n",
    "    validation_acc_history = []\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        stop_training = False\n",
    "        for i, (train_data, train_labels, length_batch) in enumerate(data_iter):\n",
    "            model.train()\n",
    "            model.zero_grad()\n",
    "            \n",
    "            if lstm:\n",
    "                hidden, c_t = model.init_hidden()\n",
    "                outputs, hidden = model(train_data, hidden, c_t)\n",
    "            else:\n",
    "                outputs = model(train_data, length_batch)\n",
    "\n",
    "            loss = criterion(outputs, train_labels.float())\n",
    "            losses.append(loss.data[0])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            if lstm:\n",
    "                hidden, c_t = model.init_hidden()\n",
    "                print(hidden.size())\n",
    "                print(valid_sequences.size())\n",
    "                val_outputs, hidden = model(Variable(valid_sequences), hidden, c_t)\n",
    "            else:\n",
    "                val_outputs = model(Variable(valid_sequences), Variable(valid_length))\n",
    "            \n",
    "            val_accuracy = calculate_accuracy(val_outputs, Variable(valid_label), num_labels)\n",
    "            validation_acc_history.append(val_accuracy)\n",
    "            f_score,threshold,precision,recall = F_score(val_outputs, valid_label)\n",
    "            stop_training = early_stop(validation_acc_history)\n",
    "\n",
    "            if stop_training:\n",
    "                print(\"earily stop triggered\")\n",
    "                break\n",
    "            \n",
    "            if (i+1) % batch_size == 0:\n",
    "                print('Epoch: [{}/{}], Step: [{}/{}], Train loss: {}, \\nF_Score: {}, Threshold: {}, Precision: {}, Recall: {}, Validation Acc: {}'\\\n",
    "                      .format(epoch, num_epochs, i+1, total_batches, np.mean(losses)/(total_batches*epoch), \\\n",
    "                        f_score, threshold, precision,recall, val_accuracy))\n",
    "        \n",
    "        if stop_training == True:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Prediction Test Data performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy_on_test_set(model, test_input_seq, test_seq_length, test_output_labels, num_labels):\n",
    "    test_input_seq = Variable(test_input_seq)\n",
    "    test_seq_length = Variable(test_seq_length)\n",
    "    test_output_labels = Variable(test_output_labels)\n",
    "    predicted = model(test_input_seq, test_seq_length)\n",
    "    accuracy_on_test_set = calculate_accuracy(predicted, test_output_labels, num_labels)\n",
    "    return accuracy_on_test_set\n",
    "\n",
    "def FScore_on_test_set(model, test_input_seq, test_seq_length, test_output_labels, num_labels):\n",
    "    test_input_seq = Variable(test_input_seq)\n",
    "    test_seq_length = Variable(test_seq_length)\n",
    "    #test_output_labels = Variable(test_output_labels)\n",
    "    predicted = model(test_input_seq, test_seq_length)\n",
    "    fmax, optimal_threshold, optimal_precision, optimal_recall = F_score(predicted, test_output_labels)\n",
    "    return fmax, optimal_threshold, optimal_precision, optimal_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Model training and test performance - FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "vocab_size = 26 # number words in the vocabulary base\n",
    "emb_dim = 20 # dimension for n-gram embedding\n",
    "num_epochs = 500 # number epoch to train\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART I - Human Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_size = len(human_train_sequences)\n",
    "num_labels = human_GO_terms.shape[0] #147\n",
    "\n",
    "model = FastText(vocab_size, emb_dim, num_labels)\n",
    "criterion = nn.MultiLabelSoftMarginLoss()  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Brenton/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:41: RuntimeWarning: invalid value encountered in true_divide\n",
      "/Users/Brenton/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:40: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/500], Step: [20/251], Train loss: 0.0035386310274382513, \n",
      "F_Score: 0.08519872708787733, Threshold: 0.21, Precision: 0.04470668031957694, Recall: 0.9037445863825889, Validation Acc: 0.8863008908032343\n",
      "Epoch: [1/500], Step: [40/251], Train loss: 0.003298604547739979, \n",
      "F_Score: 0.08529061347965258, Threshold: 0.08, Precision: 0.04470155305494888, Recall: 0.9270832135989816, Validation Acc: 0.9508397520723608\n",
      "earily stop triggered\n",
      "Test Data F-Score for yeast protein prediction is 0.0719887130174 \n",
      "Precision: 0.0395926571975 \n",
      "Recall: 0.396051453599\n"
     ]
    }
   ],
   "source": [
    "data_iter = batch_iter(human_train_vectors, human_train_labels, human_train_lengths, batch_size)\n",
    "\n",
    "# Model Training\n",
    "train_test(human_valid_vectors, human_valid_labels, human_valid_lengths, \\\n",
    "           num_epochs, optimizer, data_iter, model, data_size) \n",
    "\n",
    "FScore,_,Precision,Recall = FScore_on_test_set(model, human_test_vectors, human_test_lengths,human_test_labels, num_labels)\n",
    "\n",
    "# Prediction on test set\n",
    "print(\"Test Data F-Score for yeast protein prediction is\", FScore, '\\nPrecision:',Precision,\n",
    "      '\\nRecall:',Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART II - Yeast Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Brenton/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:41: RuntimeWarning: invalid value encountered in true_divide\n",
      "/Users/Brenton/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:40: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earily stop triggered\n",
      "Test Data F-Score for yeast protein prediction is 0.160890942372 \n",
      "Precision: 0.0906665987734 \n",
      "Recall: 0.71359223301\n"
     ]
    }
   ],
   "source": [
    "data_size = len(yeast_train_sequences) #3447\n",
    "num_labels = yeast_GO_terms.shape[0] #26\n",
    "\n",
    "model = FastText(vocab_size, emb_dim, num_labels)\n",
    "data_iter = batch_iter(yeast_train_vectors, yeast_train_labels, yeast_train_lengths, batch_size)\n",
    "\n",
    "# Model Training\n",
    "train_test(yeast_valid_vectors, yeast_valid_labels, yeast_valid_lengths, \\\n",
    "           num_epochs, optimizer, data_iter, model, data_size)\n",
    "\n",
    "FScore,_,Precision,Recall = FScore_on_test_set(model, yeast_test_vectors, yeast_test_lengths,yeast_test_labels, num_labels)\n",
    "\n",
    "# Prediction on test set\n",
    "print(\"Test Data F-Score for yeast protein prediction is\", FScore, '\\nPrecision:',Precision,\n",
    "      '\\nRecall:',Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6B) Model training and test performance - LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part I - Human Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "vocab_size = 26 # number words in the vocabulary base\n",
    "emb_dim = 20 # dimension for n-gram embedding\n",
    "num_epochs = 500 # number epoch to train\n",
    "batch_size = 40\n",
    "\n",
    "#New parameters\n",
    "hidden_size=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = len(human_train_sequences)\n",
    "num_labels = human_GO_terms.shape[0] #147\n",
    "\n",
    "model = LSTM(vocab_size, emb_dim, hidden_size, num_labels, batch_size)\n",
    "criterion = nn.MultiLabelSoftMarginLoss()  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "\n",
    "data_iter = batch_iter(human_train_vectors, human_train_labels, human_train_lengths, batch_size)\n",
    "\n",
    "# Model Training\n",
    "train_test(human_valid_vectors, human_valid_labels, human_valid_lengths, \\\n",
    "           num_epochs, optimizer, data_iter, model, data_size, lstm=True) \n",
    "\n",
    "FScore,_,Precision,Recall = FScore_on_test_set(model, human_test_vectors, human_test_lengths,human_test_labels, num_labels)\n",
    "\n",
    "# Prediction on test set\n",
    "print(\"Test Data F-Score for human protein prediction is\", FScore, '\\nPrecision:',Precision,\n",
    "      '\\nRecall:',Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 20])\n",
      "torch.Size([963, 4092])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "inconsistent tensor sizes at /Users/soumith/code/builder/wheel/pytorch-src/torch/lib/TH/generic/THTensorMath.c:2709",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-07d40e682754>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Model Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myeast_valid_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myeast_valid_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myeast_valid_lengths\u001b[0m\u001b[0;34m,\u001b[0m            \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mFScore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPrecision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mRecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFScore_on_test_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myeast_test_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myeast_test_lengths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myeast_test_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-118-0d2ff414e1cd>\u001b[0m in \u001b[0;36mtrain_test\u001b[0;34m(valid_sequences, valid_label, valid_length, num_epochs, optimizer, data_iter, model, training_length, lstm)\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_sequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 \u001b[0mval_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mval_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Brenton/anaconda/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-110-0c736a4f3d26>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data, hidden, c)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-110-0c736a4f3d26>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(emb, hid, c_t)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Brenton/anaconda/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mcat\u001b[0;34m(iterable, dim)\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mConcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Brenton/anaconda/lib/python3.5/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, dim, *inputs)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor sizes at /Users/soumith/code/builder/wheel/pytorch-src/torch/lib/TH/generic/THTensorMath.c:2709"
     ]
    }
   ],
   "source": [
    "data_size = len(yeast_train_sequences) #3447\n",
    "num_labels = yeast_GO_terms.shape[0] #26\n",
    "\n",
    "model = LSTM(vocab_size, emb_dim, hidden_size, num_labels, batch_size)\n",
    "data_iter = batch_iter(yeast_train_vectors, yeast_train_labels, yeast_train_lengths, batch_size)\n",
    "\n",
    "# Model Training\n",
    "train_test(yeast_valid_vectors, yeast_valid_labels, yeast_valid_lengths, \\\n",
    "           num_epochs, optimizer, data_iter, model, data_size, lstm=True)\n",
    "\n",
    "FScore,_,Precision,Recall = FScore_on_test_set(model, yeast_test_vectors, yeast_test_lengths,yeast_test_labels, num_labels)\n",
    "\n",
    "# Prediction on test set\n",
    "print(\"Test Data F-Score for yeast protein prediction is\", FScore, '\\nPrecision:',Precision,\n",
    "      '\\nRecall:',Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
