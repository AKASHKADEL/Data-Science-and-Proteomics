{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Loading fasta file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:35: DeprecationWarning: 'U' mode is deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Loading *.mat file...\n",
      "Number of training prots: 9751\n",
      "Number of validation prots: 3871\n",
      "Number of testing prots: 1647\n",
      "### Loading fasta file...\n",
      "### Loading *.mat file...\n",
      "Number of training prots: 3447\n",
      "Number of validation prots: 963\n",
      "Number of testing prots: 206\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "from Bio import SeqIO\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "\n",
    "pdir = '/Users/Brenton/Documents/Capstone/'\n",
    "\n",
    "def load_test_sets(filename):\n",
    "    print(\"### Loading *.mat file...\")\n",
    "    go_data = sio.loadmat(filename, squeeze_me=True)\n",
    "    go_terms = go_data['goTerm_labels'] # names of gene ontology function terms\n",
    "    train_annotations = np.asarray(go_data['trainProts_label'].todense()) # training set of function annotations\n",
    "    valid_annotations = np.asarray(go_data['validProts_label'].todense()) # valid \"\" \"\"\n",
    "    test_annotations = np.asarray(go_data['testProts_label'].todense()) # test \"\" \"\"\n",
    "    train_inds = go_data['trainProts']\n",
    "    train_inds = train_inds - 1\n",
    "    valid_inds = go_data['validProts']\n",
    "    valid_inds = valid_inds - 1\n",
    "    test_inds = go_data['testProts']\n",
    "    test_inds = test_inds - 1 # subtract 1 for matlab index conversion into python\n",
    "\n",
    "    return train_inds, valid_inds, test_inds, train_annotations, valid_annotations, test_annotations, go_terms\n",
    "\n",
    "def load_FASTA(filename):\n",
    "    \"\"\" Loads fasta file and returns a list of the Bio SeqIO records \"\"\"\n",
    "    print(\"### Loading fasta file...\")\n",
    "    infile = open(filename, 'rU')\n",
    "    full_entries = list(SeqIO.parse(infile, 'fasta'))\n",
    "    sequences = [str(entry.seq) for entry in full_entries]\n",
    "    names = [str(entry.id) for entry in full_entries]\n",
    "\n",
    "    return sequences, names\n",
    "\n",
    "#Human Sequences\n",
    "fasta = '../../data/human_sequences.fasta'\n",
    "test_set_file = '../../data/human_annotations_temporal_holdout.mat'\n",
    "\n",
    "sequences, names = load_FASTA(fasta)\n",
    "train_inds, valid_inds, test_inds, y_trainHuman, y_validHuman, y_testHuman, go_termsHuman = load_test_sets(test_set_file)\n",
    "\n",
    "train_seqsHuman = [sequences[i] for i in train_inds]\n",
    "print('Number of training prots: ' + str(len(train_seqsHuman)))\n",
    "valid_seqsHuman = [sequences[i] for i in valid_inds]\n",
    "print('Number of validation prots: ' + str(len(valid_seqsHuman)))\n",
    "test_seqsHuman = [sequences[i] for i in test_inds]\n",
    "print('Number of testing prots: ' + str(len(test_seqsHuman)))\n",
    "\n",
    "#Yeast sequences\n",
    "fasta = '../../data/yeast_sequences.fasta'\n",
    "test_set_file = '../../data/yeast_MF_temporal_holdout.mat'\n",
    "\n",
    "sequences, names = load_FASTA(fasta)\n",
    "train_inds, valid_inds, test_inds, y_trainYeast, y_validYeast, y_testYeast, go_termsYeast = load_test_sets(test_set_file)\n",
    "\n",
    "train_seqsYeast = [sequences[i] for i in train_inds]\n",
    "print('Number of training prots: ' + str(len(train_seqsYeast)))\n",
    "valid_seqsYeast = [sequences[i] for i in valid_inds]\n",
    "print('Number of validation prots: ' + str(len(valid_seqsYeast)))\n",
    "test_seqsYeast = [sequences[i] for i in test_inds]\n",
    "print('Number of testing prots: ' + str(len(test_seqsYeast)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    0     0     0  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "    0     0     0  ...      1     0     1\n",
       "       ...          â‹±          ...       \n",
       "    0     0     0  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "    0     0     0  ...      1     0     1\n",
       "[torch.LongTensor of size 3447x26]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrainYeast = torch.from_numpy(y_trainYeast).type(torch.LongTensor)\n",
    "yValidYeast = torch.from_numpy(y_validYeast).type(torch.LongTensor)\n",
    "yTestYeast = torch.from_numpy(y_testYeast).type(torch.LongTensor)\n",
    "\n",
    "yTrainHuman = torch.from_numpy(y_trainHuman).type(torch.LongTensor)\n",
    "yValidHuman = torch.from_numpy(y_validHuman).type(torch.LongTensor)\n",
    "yTestHuman = torch.from_numpy(y_testHuman).type(torch.LongTensor)\n",
    "\n",
    "yTrainYeast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the Length of train, valid and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9751 3871 1647\n",
      "3447 963 206\n"
     ]
    }
   ],
   "source": [
    "# Human data:\n",
    "\n",
    "train_seqsHuman_length = []\n",
    "[train_seqsHuman_length.append(len(train_seqsHuman[i])) for i in range(len(train_seqsHuman))]\n",
    "train_seqsHuman_length = torch.LongTensor(train_seqsHuman_length)\n",
    "\n",
    "valid_seqsHuman_length = []\n",
    "[valid_seqsHuman_length.append(len(valid_seqsHuman[i])) for i in range(len(valid_seqsHuman))]\n",
    "valid_seqsHuman_length = torch.LongTensor(valid_seqsHuman_length)\n",
    "\n",
    "test_seqsHuman_length = []\n",
    "[test_seqsHuman_length.append(len(test_seqsHuman[i])) for i in range(len(test_seqsHuman))]\n",
    "test_seqsHuman_length = torch.LongTensor(test_seqsHuman_length)\n",
    "\n",
    "print(len(train_seqsHuman_length), len(valid_seqsHuman_length), len(test_seqsHuman_length))\n",
    "\n",
    "# Yeast data:\n",
    "\n",
    "train_seqsYeast_length = []\n",
    "[train_seqsYeast_length.append(len(train_seqsYeast[i])) for i in range(len(train_seqsYeast))]\n",
    "train_seqsYeast_length = torch.LongTensor(train_seqsYeast_length)\n",
    "\n",
    "valid_seqsYeast_length = []\n",
    "[valid_seqsYeast_length.append(len(valid_seqsYeast[i])) for i in range(len(valid_seqsYeast))]\n",
    "valid_seqsYeast_length = torch.LongTensor(valid_seqsYeast_length)\n",
    "\n",
    "test_seqsYeast_length = []\n",
    "[test_seqsYeast_length.append(len(test_seqsYeast[i])) for i in range(len(test_seqsYeast))]\n",
    "test_seqsYeast_length = torch.LongTensor(test_seqsYeast_length)\n",
    "\n",
    "print(len(train_seqsYeast_length), len(valid_seqsYeast_length), len(test_seqsYeast_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize all amino-acid chains in the list \n",
    "#### Each amino-acid string becomes one row in a tensor object.\n",
    "#### This tensor object has dimension NxD, where N is the number of amino-acid strings and D is the length of the longest chain in the set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ConvertCharToInt = {'A':1, 'B':2, 'C':3, 'D':4, 'E':5, 'F':6, 'G':7, 'H':8, 'I':9, 'J':10,\n",
    "                   'K':11, 'L':12, 'M':13, 'N':14, 'O':15, 'P':16, 'Q':17, 'R':18, 'S':19,\n",
    "                   'T':20, 'U':21, 'V':22, 'W':23, 'X':24, 'Y':25, 'Z':26}\n",
    "\n",
    "def vectorize_AAs(string):\n",
    "    '''This function takes an amino-acid string as input and outputs a vector of integers, with each\n",
    "    integer representing one amino acid.\n",
    "    \n",
    "    For example, 'BACEA' is converted to [2, 1, 3, 5, 1]\n",
    "    '''\n",
    "    character_list = list(string) #converts 'BACEA' to ['B','A','C','E','A]\n",
    "    for i in range(len(character_list)):\n",
    "        character_list[i] = ConvertCharToInt[character_list[i]] #convert the character to a number\n",
    "    return character_list\n",
    "\n",
    "def AddZeros(vector, max_length):\n",
    "    '''This function adds the necessary number of zeros and returns an array'''\n",
    "    #max_length = length of longest vector in the batch\n",
    "    #oldvector = initial vector for that amino-acid chain (in integers)\n",
    "    diff = max_length - len(vector)\n",
    "    if diff>0:\n",
    "        ZerosToAdd = np.zeros(diff)\n",
    "        vector.extend(ZerosToAdd)\n",
    "    return vector \n",
    "\n",
    "def TransformAAsToTensor(ListOfSequences):\n",
    "    '''This function takes as input a list of amino acid strings and creates a tensor matrix\n",
    "    of dimension NxD, where N is the number of strings and D is the length of the longest AA chain\n",
    "    \n",
    "    \"ListOfSequences\" can be training, validation, or test sets\n",
    "    '''\n",
    "    #find longest amino-acid sequence\n",
    "    max_length = len(max(ListOfSequences, key=len))\n",
    "    Sequences = ListOfSequences.copy() \n",
    "    for AA in range(len(Sequences)): #for each amino-acid sequence\n",
    "        Sequences[AA] = vectorize_AAs(Sequences[AA])\n",
    "        Sequences[AA] = AddZeros(Sequences[AA], max_length)\n",
    "    NewTensor = torch.from_numpy(np.array(Sequences))\n",
    "    return NewTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runs quickly for Yeast, about 2 minutes for Human data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   13     3     7  ...      0     0     0\n",
       "   13     4     1  ...      0     0     0\n",
       "   13     9    11  ...      0     0     0\n",
       "       ...          â‹±          ...       \n",
       "   13    12     4  ...      0     0     0\n",
       "   13    22    19  ...      0     0     0\n",
       "   13    12    13  ...      0     0     0\n",
       "[torch.DoubleTensor of size 206x1592]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainSeqsYeast = TransformAAsToTensor(train_seqsYeast)\n",
    "ValidSeqsYeast = TransformAAsToTensor(valid_seqsYeast)\n",
    "TestSeqsYeast = TransformAAsToTensor(test_seqsYeast)\n",
    "TestSeqsYeast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   13    18    12  ...      0     0     0\n",
       "   13    13     5  ...      0     0     0\n",
       "   13    11     8  ...      0     0     0\n",
       "       ...          â‹±          ...       \n",
       "   13    18     1  ...      0     0     0\n",
       "   24     1    18  ...      0     0     0\n",
       "   13     1    12  ...      0     0     0\n",
       "[torch.DoubleTensor of size 1647x5090]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainSeqsHuman = TransformAAsToTensor(train_seqsHuman)\n",
    "ValidSeqsHuman = TransformAAsToTensor(valid_seqsHuman)\n",
    "TestSeqsHuman = TransformAAsToTensor(test_seqsHuman)\n",
    "TestSeqsHuman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Hyperparameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "vocab_size = 26 # number words in the vocabulary base\n",
    "emb_dim = 50 # dimension for n-gram embedding\n",
    "num_epochs = 5 # number epoch to train\n",
    "batch_size = 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Get batch data method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def batch_iter(TrainSeqs, yTrain, TrainSeqsLength, batch_size):\n",
    "    start = -1 * batch_size\n",
    "    dataset_size = TrainSeqs.size()[0]\n",
    "    order = list(range(dataset_size))\n",
    "    random.shuffle(order)\n",
    "\n",
    "    while True:\n",
    "        start += batch_size\n",
    "        if start > dataset_size - batch_size:\n",
    "            # Start another epoch.\n",
    "            start = 0\n",
    "            random.shuffle(order)\n",
    "        batch_indices = order[start:start + batch_size]\n",
    "        batch_indices_tensor = torch.LongTensor(batch_indices)\n",
    "        batch_train = TrainSeqs[batch_indices_tensor].type(torch.LongTensor)\n",
    "        batch_train_labels = yTrain[batch_indices_tensor]\n",
    "        length_batch = TrainSeqsLength[batch_indices_tensor]\n",
    "        yield [Variable(batch_train), Variable(batch_train_labels), Variable(length_batch)]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) FastText class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FastText(nn.Module):\n",
    "    \"\"\"\n",
    "    FastText model\n",
    "    \"\"\"\n",
    "       \n",
    "    def __init__(self, vocab_size, emb_dim, num_labels):\n",
    "       \n",
    "        \"\"\"\n",
    "        @param vocab_size: size of the vocabulary. \n",
    "        @param emb_dim: size of the word embedding\n",
    "        \"\"\"\n",
    "        super(FastText, self).__init__()\n",
    "\n",
    "        self.num_labels = num_labels\n",
    "        self.embed = nn.Embedding(vocab_size+1, emb_dim, padding_idx=0)\n",
    "        self.linear = nn.Linear(emb_dim,num_labels)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self, data, length):\n",
    "        \"\"\"\n",
    "        @param data: matrix of size (batch_size, max_sentence_length). Each row in data represents a \n",
    "            review that is represented using n-gram index. Note that they are padded to have same length.\n",
    "        @param length: an int tensor of size (batch_size), which represents the non-trivial (excludes padding)\n",
    "            length of each sentences in the data.\n",
    "        \"\"\"\n",
    "        data = data.type(torch.LongTensor)\n",
    "        out = self.embed(data)\n",
    "        out = torch.sum(out, dim=1)\n",
    "        out = out / length.view(-1,1).float()\n",
    "            \n",
    "        out = self.linear(out)\n",
    "        return nn.functional.sigmoid(out)\n",
    "    \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        lin_layers = [self.linear]\n",
    "        em_layer = [self.embed]\n",
    "     \n",
    "        for layer in lin_layers+em_layer:\n",
    "            layer.weight.data.uniform_(-initrange, initrange)\n",
    "            if layer in lin_layers:\n",
    "                layer.bias.data.fill_(0)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,average_precision_score\n",
    "\n",
    "def round_manual(data, threshold):\n",
    "    return (data >= threshold).astype(int)\n",
    "\n",
    "def calculate_accuracy(predicted, actuals, num_labels, threshold):\n",
    "    \"\"\"\n",
    "    @param predicted: data type = Variable\n",
    "    @param actuals: data type = Variable\n",
    "    @param num_labels: no of go terms\n",
    "    @return: accuracy measure\n",
    "    \"\"\"\n",
    "    predicted = round_manual(predicted.data.numpy(), threshold)\n",
    "    total_predictions = actuals.size()[0]\n",
    "    accuracy = np.sum(predicted==actuals.data.numpy())/(total_predictions*num_labels)\n",
    "    return accuracy\n",
    "\n",
    "def average_precision(predicted, actuals, threshold):\n",
    "    \"\"\"\n",
    "    @param predicted: data type = Variable\n",
    "    @param actuals: data type = Variable\n",
    "    @param num_labels: no of go terms\n",
    "    @return: precision\n",
    "    \"\"\"\n",
    "    actuals = actuals.data.numpy()\n",
    "    predicted = round_manual(predicted.data.numpy(), threshold)\n",
    "    non_zero_go_terms = np.count_nonzero((np.sum(actuals, axis=0)!=0).astype(int))\n",
    "    return np.sum(precision_score(actuals, predicted, average=None))/non_zero_go_terms\n",
    "    \n",
    "def average_recall(predicted, actuals, threshold):\n",
    "    \"\"\"\n",
    "    @param predicted: data type = Variable\n",
    "    @param actuals: data type = Variable\n",
    "    @param num_labels: no of go terms\n",
    "    @return: recall\n",
    "    \"\"\"\n",
    "    actuals = actuals.data.numpy()\n",
    "    predicted = round_manual(predicted.data.numpy(), threshold)\n",
    "    non_zero_go_terms = np.count_nonzero((np.sum(actuals, axis=0)!=0).astype(int))\n",
    "    return np.sum(recall_score(actuals, predicted, average=None))/non_zero_go_terms\n",
    "\n",
    "def F_score(precision_score, recall_score):\n",
    "    return ((2*precision_score*recall_score) / (precision_score + recall_score))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Early stop condition and training stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def early_stop(val_acc_history, t=2, required_progress=0.001):\n",
    "    \"\"\"\n",
    "    Stop the training if there is no non-trivial progress in k steps\n",
    "    @param val_acc_history: a list contains all the historical validation acc\n",
    "    @param required_progress: the next acc should be higher than the previous by \n",
    "        at least required_progress amount to be non-trivial\n",
    "    @param t: number of training steps \n",
    "    @return: a boolean indicates if the model should earily stop\n",
    "    \"\"\"\n",
    "    # TODO: add your code here\n",
    "    \n",
    "    cnt = 0 # initialize the count --> to store count of cases where difference in\n",
    "                                    #  accuracy is less than required progress.\n",
    "    \n",
    "    if(len(val_acc_history) > 0): # if list has size > 0 \n",
    "        for i in range(t): # start the loop\n",
    "            index = len(val_acc_history) - (i+1) # start from the last term in list and move to the left\n",
    "            if (index >= 1): # to check if index != 0 --> else we can't compare to previous value\n",
    "                if ((val_acc_history[index] - val_acc_history[index-1]) < required_progress):\n",
    "                    cnt += 1 # increase the count value\n",
    "                else:\n",
    "                    break # break if difference is grea-ter \n",
    "    \n",
    "    if(cnt != t): # if count is equal to t, return True\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "    \n",
    "def train_test(valid_sequences, valid_label, valid_length, num_epochs, optimizer, data_iter, model, training_length, threshold):\n",
    "    losses = []\n",
    "    total_batches = int(training_length/ batch_size) #375\n",
    "    validation_acc_history = []\n",
    "    calculated_f_score = None\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        stop_training = False\n",
    "        for i, (train_data, train_labels, length_batch) in enumerate(data_iter):\n",
    "            model.train()\n",
    "            model.zero_grad()\n",
    "            outputs = model(train_data, length_batch)\n",
    "            loss = criterion(outputs, train_labels.float())\n",
    "            losses.append(loss.data[0])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            val_outputs = model(Variable(valid_sequences), Variable(valid_length))\n",
    "            val_accuracy = calculate_accuracy(val_outputs, Variable(valid_label), num_labels, threshold)\n",
    "            validation_acc_history.append(val_accuracy)\n",
    "            \n",
    "            # calculating precision and recall based on CAFA's definition\n",
    "            ave_precision = average_precision(val_outputs, Variable(valid_label), threshold)\n",
    "            ave_recall = average_recall(val_outputs, Variable(valid_label), threshold)\n",
    "            f_score = F_score(ave_precision, ave_recall)\n",
    "            calculated_f_score = f_score\n",
    "            #stop_training = early_stop(validation_acc_history)\n",
    "            \n",
    "            if stop_training:\n",
    "                print(\"earily stop triggered\")\n",
    "                break\n",
    "            if (i+1) % 80 == 0:\n",
    "                print('Epoch: [{0}/{1}], Step: [{2}/{3}], Train loss: {4}, F_Score: {5}, Validation Acc:{6}'.format( \n",
    "                           epoch, num_epochs, i+1, total_batches, np.mean(losses)/(total_batches*epoch), f_score, val_accuracy))\n",
    "        if stop_training == True:\n",
    "            break\n",
    "            \n",
    "    return calculated_f_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Prediction Test Data performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy_on_test_set(model, test_input_seq, test_seq_length, test_output_labels, num_labels, threshold):\n",
    "    test_input_seq = Variable(test_input_seq)\n",
    "    test_seq_length = Variable(test_seq_length)\n",
    "    test_output_labels = Variable(test_output_labels)\n",
    "    predicted = model(test_input_seq, test_seq_length)\n",
    "    accuracy_on_test_set = calculate_accuracy(predicted, test_output_labels, num_labels, threshold)\n",
    "    return accuracy_on_test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Model training and test performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART I - Human Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_size = len(train_seqsHuman) #9751\n",
    "num_labels = go_termsHuman.shape[0] #147\n",
    "\n",
    "model = FastText(vocab_size, emb_dim, num_labels)\n",
    "criterion = nn.MultiLabelSoftMarginLoss()  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/1], Step: [80/375], Train loss: 0.0026038429776827493, F_Score: 0.08474049982457527, Validation Acc:0.05384535627735982\n",
      "Epoch: [1/1], Step: [160/375], Train loss: 0.0026046042690674462, F_Score: 0.08474049982457527, Validation Acc:0.05384535627735982\n",
      "Epoch: [1/1], Step: [240/375], Train loss: 0.0026044170008765327, F_Score: 0.08474049982457527, Validation Acc:0.05384535627735982\n",
      "Epoch: [1/1], Step: [320/375], Train loss: 0.0026046884228785832, F_Score: 0.08474049982457527, Validation Acc:0.05384535627735982\n",
      "Epoch: [1/1], Step: [400/375], Train loss: 0.002604691073894501, F_Score: 0.08474049982457527, Validation Acc:0.05384535627735982\n",
      "Epoch: [1/1], Step: [480/375], Train loss: 0.0026048032104969026, F_Score: 0.08474049982457527, Validation Acc:0.05384535627735982\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-35f15959b16a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFastText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mValidSeqsHuman\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myValidHuman\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_seqsHuman_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mf_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-41a316983fbf>\u001b[0m in \u001b[0;36mtrain_test\u001b[0;34m(valid_sequences, valid_label, valid_length, num_epochs, optimizer, data_iter, model, training_length, threshold)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mval_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_sequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mval_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mvalidation_acc_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\akash\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-b16f29132970>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data, length)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\akash\\Anaconda3\\lib\\site-packages\\torch\\autograd\\variable.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(self, dim, keepdim)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mSum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\akash\\Anaconda3\\lib\\site-packages\\torch\\autograd\\_functions\\reduce.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input, dim, keepdim)\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_iter = batch_iter(TrainSeqsHuman, yTrainHuman, train_seqsHuman_length, batch_size)\n",
    "\n",
    "num_epochs = 1\n",
    "threshold = [0.1, 0.2, 0.3, 0.4, 0.5, 0,6, 0.7, 0.8, 0.9]\n",
    "f_score = []\n",
    "\n",
    "# Model Training\n",
    "for i in threshold:\n",
    "    model = FastText(vocab_size, emb_dim, num_labels)\n",
    "    f = train_test(ValidSeqsHuman, yValidHuman, valid_seqsHuman_length, num_epochs, optimizer, data_iter, model, data_size, i)\n",
    "    f_score.append(f)\n",
    "    \n",
    "# Prediction on test set\n",
    "print(\"Test Data accuracy for human protein prediction is\", accuracy_on_test_set(model, TestSeqsHuman, test_seqsHuman_length, yTestHuman, num_labels, threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-b274ddcf82ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'threshold'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'F_Score'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(threshold, f_score)\n",
    "plt.xlabel('threshold')\n",
    "plt.ylabel('F_Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART II - Yeast Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earily stop triggered\n",
      "Test Data accuracy for yeast protein prediction is 0.0905526512323\n"
     ]
    }
   ],
   "source": [
    "data_size = len(train_seqsYeast) #3447\n",
    "num_labels = go_termsYeast.shape[0] #26\n",
    "\n",
    "num_epochs = 1\n",
    "threshold = [0.1, 0.2, 0.3, 0.4, 0.5, 0,6, 0.7, 0.8, 0.9]\n",
    "\n",
    "model = FastText(vocab_size, emb_dim, num_labels)\n",
    "data_iter = batch_iter(TrainSeqsYeast, yTrainYeast, train_seqsYeast_length, batch_size)\n",
    "f_score = []\n",
    "\n",
    "# Model Training\n",
    "for i in threshold:\n",
    "    model = FastText(vocab_size, emb_dim, num_labels)\n",
    "    f = train_test(ValidSeqsYeast, yValidYeast, valid_seqsYeast_length, num_epochs, optimizer, data_iter, model, data_size, threshold)\n",
    "    f_score.append(f)\n",
    "    \n",
    "\n",
    "# Prediction on test set\n",
    "print(\"Test Data accuracy for yeast protein prediction is\", accuracy_on_test_set(model, TestSeqsYeast, test_seqsYeast_length, yTestYeast, num_labels, threshold))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
