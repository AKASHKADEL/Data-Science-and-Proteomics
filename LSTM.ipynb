{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "from Bio import SeqIO\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "def load_test_sets(filename):\n",
    "    go_data = sio.loadmat(filename, squeeze_me=True)\n",
    "    go_terms = go_data['goTerm_labels'] # names of gene ontology function terms\n",
    "    train_annotations = np.asarray(go_data['trainProts_label'].todense()) # training set of function annotations\n",
    "    valid_annotations = np.asarray(go_data['validProts_label'].todense()) # valid \"\" \"\"\n",
    "    test_annotations = np.asarray(go_data['testProts_label'].todense()) # test \"\" \"\"\n",
    "    train_inds = go_data['trainProts']\n",
    "    train_inds = train_inds - 1\n",
    "    valid_inds = go_data['validProts']\n",
    "    valid_inds = valid_inds - 1\n",
    "    test_inds = go_data['testProts']\n",
    "    test_inds = test_inds - 1 # subtract 1 for matlab index conversion into python\n",
    "\n",
    "    return train_inds, valid_inds, test_inds, train_annotations, valid_annotations, test_annotations, go_terms\n",
    "\n",
    "def load_FASTA(filename):\n",
    "    \"\"\" Loads fasta file and returns a list of the Bio SeqIO records \"\"\"\n",
    "    infile = open(filename)\n",
    "    full_entries = list(SeqIO.parse(infile, 'fasta'))\n",
    "    sequences = [str(entry.seq) for entry in full_entries]\n",
    "    names = [str(entry.id) for entry in full_entries]\n",
    "\n",
    "    return sequences, names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load human sequences and create train/dev/test sets, create lengths for FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "human_sequences, human_protein_names = load_FASTA('../data/human_sequences.fasta')\n",
    "human_train_idx, human_valid_idx, human_test_idx, human_train_labels, human_valid_labels, \\\n",
    "    human_test_labels, human_GO_terms = load_test_sets('../data/human_annotations_temporal_holdout.mat')\n",
    "\n",
    "# Create train, validation, and test sets from the full list of human proteins\n",
    "human_train_sequences = [human_sequences[i] for i in human_train_idx]\n",
    "human_valid_sequences = [human_sequences[i] for i in human_valid_idx]\n",
    "human_test_sequences = [human_sequences[i] for i in human_test_idx]\n",
    "\n",
    "# Convert corresponding labels for train, validation, and test sets from the full list of human proteins.\n",
    "human_train_labels = torch.from_numpy(human_train_labels).type(torch.LongTensor)\n",
    "human_valid_labels = torch.from_numpy(human_valid_labels).type(torch.LongTensor)\n",
    "human_test_labels = torch.from_numpy(human_test_labels).type(torch.LongTensor)\n",
    "\n",
    "# Create lengths for sequence representation averaging in FastText\n",
    "human_train_lengths = torch.LongTensor([len(human_train_sequences[i]) for i in range(len(human_train_sequences))])\n",
    "human_valid_lengths = torch.LongTensor([len(human_valid_sequences[i]) for i in range(len(human_valid_sequences))])\n",
    "human_test_lengths = torch.LongTensor([len(human_test_sequences[i]) for i in range(len(human_test_sequences))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load yeast sequences and create train/dev/test sets, create lengths for FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load yeast sequences and training data\n",
    "yeast_sequences, yeast_protein_names = load_FASTA('../data/yeast_sequences.fasta')\n",
    "yeast_train_idx, yeast_valid_idx, yeast_test_idx, yeast_train_labels, yeast_valid_labels, \\\n",
    "    yeast_test_labels, yeast_GO_terms = load_test_sets('../data/yeast_MF_temporal_holdout.mat')\n",
    "\n",
    "# Create train, validation, and test sets from the full list of yeast proteins\n",
    "yeast_train_sequences = [yeast_sequences[i] for i in yeast_train_idx]\n",
    "yeast_valid_sequences = [yeast_sequences[i] for i in yeast_valid_idx]\n",
    "yeast_test_sequences = [yeast_sequences[i] for i in yeast_test_idx]\n",
    "\n",
    "# Convert corresponding labels for train, validation, and test sets from the full list of yeast proteins.\n",
    "yeast_train_labels = torch.from_numpy(yeast_train_labels).type(torch.LongTensor)\n",
    "yeast_valid_labels = torch.from_numpy(yeast_valid_labels).type(torch.LongTensor)\n",
    "yeast_test_labels = torch.from_numpy(yeast_test_labels).type(torch.LongTensor)\n",
    "\n",
    "# Create lengths for sequence representation averaging in FastText\n",
    "yeast_train_lengths = torch.LongTensor([len(yeast_train_sequences[i]) for i in range(len(yeast_train_sequences))])\n",
    "yeast_valid_lengths = torch.LongTensor([len(yeast_valid_sequences[i]) for i in range(len(yeast_valid_sequences))])\n",
    "yeast_test_lengths = torch.LongTensor([len(yeast_test_sequences[i]) for i in range(len(yeast_test_sequences))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed amino-acid chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Each amino-acid string becomes an NxD entry in a tensor, where N is the number of \n",
    "# amino-acid strings and D is the length of the longest chain in the set. \n",
    "\n",
    "ConvertCharToInt = {'A':1, 'B':2, 'C':3, 'D':4, 'E':5, 'F':6, 'G':7, 'H':8, 'I':9, 'J':10,\n",
    "                   'K':11, 'L':12, 'M':13, 'N':14, 'O':15, 'P':16, 'Q':17, 'R':18, 'S':19,\n",
    "                   'T':20, 'U':21, 'V':22, 'W':23, 'X':24, 'Y':25, 'Z':26}\n",
    "\n",
    "def vectorize_AAs(string):\n",
    "    '''This function takes an amino-acid string as input and outputs a vector of integers, with each\n",
    "    integer representing one amino acid.\n",
    "    \n",
    "    For example, 'BACEA' is converted to [2, 1, 3, 5, 1]\n",
    "    '''\n",
    "    character_list = list(string) #converts 'BACEA' to ['B','A','C','E','A]\n",
    "    for i in range(len(character_list)):\n",
    "        character_list[i] = ConvertCharToInt[character_list[i]] #convert the character to a number\n",
    "    return character_list\n",
    "\n",
    "def AddZeros(vector, max_length):\n",
    "    '''This function adds the necessary number of zeros and returns an array'''\n",
    "    #max_length = length of longest vector in the batch\n",
    "    #oldvector = initial vector for that amino-acid chain (in integers)\n",
    "    diff = max_length - len(vector)\n",
    "    if diff>0:\n",
    "        ZerosToAdd = np.zeros(diff)\n",
    "        vector.extend(ZerosToAdd)\n",
    "    return vector \n",
    "\n",
    "def TransformAAsToTensor(ListOfSequences):\n",
    "    '''This function takes as input a list of amino acid strings and creates a tensor matrix\n",
    "    of dimension NxD, where N is the number of strings and D is the length of the longest AA chain\n",
    "    \n",
    "    \"ListOfSequences\" can be training, validation, or test sets\n",
    "    '''\n",
    "    #find longest amino-acid sequence\n",
    "    max_length = len(max(ListOfSequences, key=len))\n",
    "    Sequences = ListOfSequences.copy() \n",
    "    for AA in range(len(Sequences)): #for each amino-acid sequence\n",
    "        Sequences[AA] = vectorize_AAs(Sequences[AA])\n",
    "        Sequences[AA] = AddZeros(Sequences[AA], max_length)\n",
    "    NewTensor = torch.from_numpy(np.array(Sequences))\n",
    "    return NewTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "human_train_vectors = TransformAAsToTensor(human_train_sequences)\n",
    "human_valid_vectors = TransformAAsToTensor(human_valid_sequences)\n",
    "human_test_vectors = TransformAAsToTensor(human_test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yeast_train_vectors = TransformAAsToTensor(yeast_train_sequences)\n",
    "yeast_valid_vectors = TransformAAsToTensor(yeast_valid_sequences)\n",
    "yeast_test_vectors = TransformAAsToTensor(yeast_test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   13    19     4  ...      0     0     0\n",
       "   13    19    13  ...      0     0     0\n",
       "   13    22    18  ...      0     0     0\n",
       "       ...          ⋱          ...       \n",
       "   13    19     5  ...      0     0     0\n",
       "   13    22    11  ...      0     0     0\n",
       "   13    22    17  ...      0     0     0\n",
       "[torch.DoubleTensor of size 963x4092]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yeast_valid_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Get batch data method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) LSTM class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn.Embedding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM model\n",
    "    \"\"\"  \n",
    "    def __init__(self, vocab_size, emb_dim, hidden_size, num_labels, batch_size, validation_size,\n",
    "                test_size):\n",
    "        \"\"\"\n",
    "        @param vocab_size: size of the vocabulary. \n",
    "        @param emb_dim: size of the word embedding\n",
    "        \"\"\"\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.emb_dim = emb_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.validation_size = validation_size\n",
    "        self.test_size = test_size\n",
    "\n",
    "        #self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.linear_f = nn.Linear(emb_dim + hidden_size, hidden_size)\n",
    "        self.linear_i = nn.Linear(emb_dim + hidden_size, hidden_size)\n",
    "        self.linear_ctilde = nn.Linear(emb_dim + hidden_size, hidden_size)\n",
    "        self.linear_o = nn.Linear(emb_dim + hidden_size, hidden_size)\n",
    "    \n",
    "        self.decoder = nn.Linear(hidden_size, num_labels)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self, data, hidden, c, valid = False):\n",
    "        \"\"\"\n",
    "        @param data: matrix of size (batch_size, max_sentence_length). Each row in data represents a \n",
    "            review that is represented using n-gram index. Note that they are padded to have same length.\n",
    "        @param length: an int tensor of size (batch_size), which represents the non-trivial (excludes padding)\n",
    "            length of each sentences in the data.\n",
    "        \"\"\"\n",
    "        data = data.type(torch.LongTensor)\n",
    "        print(data)\n",
    "        emb = self.embed(data)\n",
    "        print(emb)\n",
    "        embs = torch.chunk(emb, emb.size()[1], 1)\n",
    "        \n",
    "        def step(emb, hid, c_t):\n",
    "            combined = torch.cat((hid,emb),1)\n",
    "            f = F.sigmoid(self.linear_f(combined))\n",
    "            i = F.sigmoid(self.linear_i(combined))\n",
    "            c_tilde = F.tanh(self.linear_ctilde(combined))\n",
    "            c_t = f*c_t + i*c_tilde\n",
    "            o = F.sigmoid(self.linear_o(combined))\n",
    "            hid = o * F.tanh(c_t)\n",
    "            return hid, c_t\n",
    "        \n",
    "        for i in range(len(embs)):\n",
    "            hidden, c = step(embs[i].squeeze(), hidden, c)\n",
    "        output = self.decoder(hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        h0 = Variable(torch.zeros(self.batch_size, self.hidden_size))\n",
    "        c0 = Variable(torch.zeros(self.batch_size, self.hidden_size))\n",
    "        return h0, c0\n",
    "    \n",
    "    def init_hidden_validation(self):\n",
    "        h0 = Variable(torch.zeros(self.validation_size, self.hidden_size))\n",
    "        c0 = Variable(torch.zeros(self.validation_size, self.hidden_size))\n",
    "        return h0, c0\n",
    "    \n",
    "    def init_hidden_test(self):\n",
    "        h0 = Variable(torch.zeros(self.test_size, self.test_size))\n",
    "        c0 = Variable(torch.zeros(self.test_size, self.test_size))\n",
    "        return h0, c0\n",
    "        \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        lin_layers = [self.linear_f, self.linear_i, self.linear_ctilde, self.linear_o]\n",
    "        em_layer = [self.embed]\n",
    "     \n",
    "        for layer in lin_layers+em_layer:\n",
    "            layer.weight.data.uniform_(-initrange, initrange)\n",
    "            if layer in lin_layers:\n",
    "                layer.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def batch_iter(TrainSeqs, yTrain, TrainSeqsLength, batch_size):\n",
    "    start = -1 * batch_size\n",
    "    dataset_size = TrainSeqs.size()[0]\n",
    "    order = list(range(dataset_size))\n",
    "    random.shuffle(order)\n",
    "\n",
    "    while True:\n",
    "        start += batch_size\n",
    "        if start > dataset_size - batch_size:\n",
    "            # Start another epoch.\n",
    "            start = 0\n",
    "            random.shuffle(order)\n",
    "        batch_indices = order[start:start + batch_size]\n",
    "        batch_indices_tensor = torch.LongTensor(batch_indices)\n",
    "        batch_train = TrainSeqs[batch_indices_tensor].type(torch.LongTensor)\n",
    "        batch_train_labels = yTrain[batch_indices_tensor]\n",
    "        length_batch = TrainSeqsLength[batch_indices_tensor]\n",
    "        yield [Variable(batch_train), Variable(batch_train_labels), Variable(length_batch)]  \n",
    "        \n",
    "    \n",
    "def eval_iter(source, batch_size):\n",
    "    batches = []\n",
    "    dataset_size = len(source)\n",
    "    start = -1 * batch_size\n",
    "    order = list(range(dataset_size))\n",
    "    random.shuffle(order)\n",
    "\n",
    "    while start < dataset_size - batch_size:\n",
    "        start += batch_size\n",
    "        batch_indices = order[start:start + batch_size]\n",
    "        batch = [source[index] for index in batch_indices]\n",
    "        if len(batch) == batch_size:\n",
    "            batches.append(batch)\n",
    "        else:\n",
    "            continue\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Evaluation Metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,average_precision_score\n",
    "\n",
    "def round_manual(data, threshold):\n",
    "    return (data >= threshold).astype(int)\n",
    "\n",
    "def calculate_accuracy(predicted, actuals, num_labels):\n",
    "    \"\"\"\n",
    "    @param predicted: data type = Variable\n",
    "    @param actuals: data type = Variable\n",
    "    @param num_labels: no of go terms\n",
    "    @return: accuracy measure\n",
    "    \"\"\"\n",
    "    predicted = np.round(predicted.data.numpy())\n",
    "    total_predictions = actuals.size()[0]\n",
    "    accuracy = np.sum(predicted==actuals.data.numpy())/(total_predictions*num_labels)\n",
    "    return accuracy\n",
    "\n",
    "def recall_precision_ProteinMethod(predicted, actual):\n",
    "    '''\n",
    "    Overall, this function calculates the recall and precision of the validation set proteins.\n",
    "    The function FIRST calculates the precision and recall values of INDIVIDUAL proteins. \n",
    "    It then takes the mean average of these values to get \"dataset-level\" precision and recall.\n",
    "    '''\n",
    "    \n",
    "    PositivesPerRow = actual.numpy().sum(axis=1) #number of functions for each protein\n",
    "    PosPredictionsPerRow = predicted.sum(axis=1) #number of predictions for each protein\n",
    "    TPs = np.multiply(actual.numpy(), predicted) #element-wise multiplication: 1 if TP, else 0\n",
    "    TPsPerRow = TPs.sum(axis=1) #number of true positives for each protein\n",
    "    \n",
    "    #PrecisionPerRow (Protein) - if protein has 0 positive predictions, the protein's precision = 0.\n",
    "    #Else, the protein's precision = TPs/PositivePreds\n",
    "    PrecisionPerRow = np.where(PosPredictionsPerRow == 0, 0, TPsPerRow/PosPredictionsPerRow)\n",
    "    RecallPerRow = np.where(PositivesPerRow==0, 0, TPsPerRow/PositivesPerRow) #Recall per Protein\n",
    "    \n",
    "    #RecallScore = average of individual protein recall scores\n",
    "    RecallScore = sum(RecallPerRow)/len(RecallPerRow) #denominator is non-zero\n",
    "    \n",
    "    #PrecisionScore = average of CERTAIN individual protein precision scores (see line below)\n",
    "    #Only consider rows with at least one predicted Go-Term.\n",
    "    #Note that some proteins can have Precision=0 but still have predictions.\n",
    "    if sum(PrecisionPerRow)>0:\n",
    "        PrecisionScore = sum(PrecisionPerRow)/len([x for x in PosPredictionsPerRow if x!=0]) \n",
    "    else:\n",
    "        PrecisionScore = 0\n",
    "    return RecallScore, PrecisionScore\n",
    "\n",
    "\n",
    "def recall_precision_GoTermMethod(predicted, actual):\n",
    "    '''\n",
    "    The function FIRST calculates the precision and recall values of INDIVIDUAL Go-Terms. \n",
    "    It then takes the mean average of these values to get \"dataset-level\" precision and recall.\n",
    "    '''\n",
    "    PositivesPerGoTerm = actual.numpy().sum(axis=0) #number of functions for each protein\n",
    "    PosPredictionsPerGoTerm = predicted.sum(axis=0) #number of predictions for each protein\n",
    "    TPs = np.multiply(actual.numpy(), predicted) #element-wise multiplication: 1 if TP, else 0\n",
    "    TPsPerGoTerm = TPs.sum(axis=0) #number of true positives for each protein\n",
    "    \n",
    "    PrecisionPerGoTerm = np.where(PosPredictionsPerGoTerm == 0, 0, TPsPerGoTerm/PosPredictionsPerGoTerm)\n",
    "    RecallPerGoTerm = np.where(PositivesPerGoTerm==0, 0, TPsPerGoTerm/PositivesPerGoTerm) #Recall per Protein\n",
    "    \n",
    "    #RecallScore = average of individual Go Term recall scores\n",
    "    RecallScore = sum(RecallPerGoTerm)/len(RecallPerGoTerm) #denominator is non-zero\n",
    "    PrecisionScore = sum(PrecisionPerGoTerm)/len(PrecisionPerGoTerm)\n",
    "    return RecallScore, PrecisionScore\n",
    "\n",
    "\n",
    "def F_score(predicted, actuals, method = 'GoTerm'):\n",
    "    \"\"\"\n",
    "    @param predicted: data type = Variable\n",
    "    @param actuals: data type = Variable\n",
    "    @return: Maximum f score over all values of tau and the corresponding tau threshold\n",
    "    \"\"\"\n",
    "    f_max, optimal_threshold, optimal_precision, optimal_recall = 0, 0, 0, 0\n",
    "    for threshold in [i/100 for i in range(1,100)]:\n",
    "        predicted_tau = round_manual(predicted.data.numpy(), threshold)\n",
    "        \n",
    "        if method == 'GoTerm':\n",
    "            recall_score, precision_score = recall_precision_GoTermMethod(predicted_tau, actuals)   \n",
    "        elif method == 'Protein':\n",
    "            recall_score, precision_score = recall_precision_ProteinMethod(predicted_tau, actuals)\n",
    "\n",
    "        if recall_score==0 and precision_score==0:\n",
    "            output = 0\n",
    "        else:\n",
    "            output = ((2*precision_score*recall_score) / (precision_score + recall_score))\n",
    "        if output > f_max:\n",
    "            f_max = output\n",
    "            optimal_threshold = threshold\n",
    "            optimal_precision = precision_score\n",
    "            optimal_recall = recall_score\n",
    "    \n",
    "    return f_max, optimal_threshold, optimal_precision, optimal_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Early stop condition and training stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def early_stop(val_loss_history, t=3, required_progress=0.001):\n",
    "    \"\"\"\n",
    "    Stop the training if there is no non-trivial progress in k steps\n",
    "    @param val_acc_history: a list contains all the historical validation acc\n",
    "    @param required_progress: the next acc should be higher than the previous by \n",
    "        at least required_progress amount to be non-trivial\n",
    "    @param t: number of training steps \n",
    "    @return: a boolean indicates if the model should earily stop\n",
    "    \"\"\"    \n",
    "    cnt = 0 # initialize the count --> to store count of cases where difference in\n",
    "                                    #  accuracy is less than required progress.\n",
    "    if(len(val_loss_history) > 0): # if list has size > 0 \n",
    "        for i in range(t): # start the loop\n",
    "            index = len(val_loss_history) - (i+1) # start from the last term in list and move to the left\n",
    "            if (index >= 1): # to check if index != 0 --> else we can't compare to previous value\n",
    "                if ((val_loss_history[index-1] - val_loss_history[index]) < required_progress):\n",
    "                    cnt += 1 # increase the count value\n",
    "                else:\n",
    "                    break # break if difference is greater \n",
    "    \n",
    "    if(cnt != t): # if count is equal to t, return True\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_test_LSTM(valid_sequences, valid_label, valid_length, num_epochs, optimizer, data_iter,\n",
    "               model, training_length, lstm=True):\n",
    "    losses = []\n",
    "    total_batches = int(training_length/ batch_size)\n",
    "    print(total_batches)\n",
    "    validation_loss_history = []\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        stop_training = False\n",
    "        for i, (train_data, train_labels, length_batch) in enumerate(data_iter):\n",
    "            print(i)\n",
    "            model.train()\n",
    "            model.zero_grad()\n",
    "            if lstm == True:\n",
    "                hidden, c_t = model.init_hidden()\n",
    "                outputs, hidden = model(train_data, hidden, c_t)\n",
    "            loss = criterion(outputs, train_labels.float())\n",
    "            print(loss)\n",
    "            losses.append(loss.data[0])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if i % batch_size/10 == 0:\n",
    "                model.eval()\n",
    "                if lstm == True:\n",
    "                    hidden, c_t = model.init_hidden_validation()\n",
    "                    print(hidden)\n",
    "                    print(valid_sequences)\n",
    "                    val_outputs, hidden = model(valid_sequences, hidden, c_t, valid=True)\n",
    "                \n",
    "                f_score,threshold,precision,recall = F_score(val_outputs, valid_label)\n",
    "                validation_loss = criterion(val_outputs, Variable(valid_label).float()).data[0]\n",
    "                validation_loss_history.append(validation_loss)\n",
    "                stop_training = early_stop(validation_loss_history)\n",
    "                \n",
    "                print('Epoch: [{}/{}], Step: [{}/{}], Train loss: {}, Validation loss for batch: {},\\nValid F_Score: {}, Threshold: {}, Valid Precision: {}, Valid Recall: {}'\\\n",
    "                      .format(epoch, num_epochs, i+1, total_batches, np.mean(losses)/(total_batches*epoch), \\\n",
    "                        validation_loss, f_score, threshold, precision,recall)) \n",
    "            \n",
    "                if stop_training:\n",
    "                    print(\"earily stop triggered\")\n",
    "                    break\n",
    "                \n",
    "        if stop_training == True:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FScore_on_test_set(model, test_input_seq, test_seq_length, test_output_labels, num_labels):\n",
    "    test_input_seq = Variable(test_input_seq)\n",
    "    test_seq_length = Variable(test_seq_length)\n",
    "    predicted = model(test_input_seq, test_seq_length)\n",
    "    fmax, optimal_threshold, optimal_precision, optimal_recall = F_score(predicted, test_output_labels)\n",
    "    return fmax, optimal_threshold, optimal_precision, optimal_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "vocab_size = 26 # number words in the vocabulary base\n",
    "emb_dim = 20 # dimension for n-gram embedding\n",
    "num_epochs = 500 # number epoch to train\n",
    "batch_size = 40\n",
    "\n",
    "#New parameters\n",
    "hidden_size=20\n",
    "validation_size = yeast_valid_vectors.size()[0]\n",
    "test_size = yeast_test_vectors.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n",
      "0\n",
      "Variable containing:\n",
      "   13     7    18  ...      0     0     0\n",
      "   13    12    19  ...      0     0     0\n",
      "   13    11    14  ...      0     0     0\n",
      "       ...          ⋱          ...       \n",
      "   13    18    19  ...      0     0     0\n",
      "   13    22    19  ...      0     0     0\n",
      "   13    19     7  ...      0     0     0\n",
      "[torch.LongTensor of size 40x4910]\n",
      "\n",
      "Variable containing:\n",
      "( 0  ,.,.) = \n",
      "1.00000e-02 *\n",
      " -4.1483 -5.6160  9.6920  ...   7.3403  0.1617 -9.8408\n",
      " -6.4610  6.8840 -4.4446  ...  -6.9465  9.6963  7.1842\n",
      " -1.7200  0.5379  5.2184  ...  -0.6741  0.6950  8.5302\n",
      "           ...             ⋱             ...          \n",
      " -6.0035  0.0641 -1.3876  ...   9.5362  4.3400  3.5494\n",
      " -6.0035  0.0641 -1.3876  ...   9.5362  4.3400  3.5494\n",
      " -6.0035  0.0641 -1.3876  ...   9.5362  4.3400  3.5494\n",
      "\n",
      "( 1  ,.,.) = \n",
      "1.00000e-02 *\n",
      " -4.1483 -5.6160  9.6920  ...   7.3403  0.1617 -9.8408\n",
      "  9.8454  6.4843  5.4318  ...  -5.7086  7.3396  6.2242\n",
      " -9.2310  2.0112  7.0523  ...  -2.4429  9.5504 -8.1568\n",
      "           ...             ⋱             ...          \n",
      " -6.0035  0.0641 -1.3876  ...   9.5362  4.3400  3.5494\n",
      " -6.0035  0.0641 -1.3876  ...   9.5362  4.3400  3.5494\n",
      " -6.0035  0.0641 -1.3876  ...   9.5362  4.3400  3.5494\n",
      "\n",
      "( 2  ,.,.) = \n",
      "1.00000e-02 *\n",
      " -4.1483 -5.6160  9.6920  ...   7.3403  0.1617 -9.8408\n",
      " -0.7957 -7.8916 -8.0805  ...   9.9620  2.0735  6.1533\n",
      "  4.7228 -7.5731  9.9199  ...  -3.6633  8.8007 -9.6508\n",
      "           ...             ⋱             ...          \n",
      " -6.0035  0.0641 -1.3876  ...   9.5362  4.3400  3.5494\n",
      " -6.0035  0.0641 -1.3876  ...   9.5362  4.3400  3.5494\n",
      " -6.0035  0.0641 -1.3876  ...   9.5362  4.3400  3.5494\n",
      " ... \n",
      "\n",
      "( 37 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -4.1483 -5.6160  9.6920  ...   7.3403  0.1617 -9.8408\n",
      " -1.7200  0.5379  5.2184  ...  -0.6741  0.6950  8.5302\n",
      " -9.2310  2.0112  7.0523  ...  -2.4429  9.5504 -8.1568\n",
      "           ...             ⋱             ...          \n",
      " -6.0035  0.0641 -1.3876  ...   9.5362  4.3400  3.5494\n",
      " -6.0035  0.0641 -1.3876  ...   9.5362  4.3400  3.5494\n",
      " -6.0035  0.0641 -1.3876  ...   9.5362  4.3400  3.5494\n",
      "\n",
      "( 38 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -4.1483 -5.6160  9.6920  ...   7.3403  0.1617 -9.8408\n",
      "  9.0768  2.5911  0.7109  ...  -9.0532 -5.8575  4.2680\n",
      " -9.2310  2.0112  7.0523  ...  -2.4429  9.5504 -8.1568\n",
      "           ...             ⋱             ...          \n",
      " -6.0035  0.0641 -1.3876  ...   9.5362  4.3400  3.5494\n",
      " -6.0035  0.0641 -1.3876  ...   9.5362  4.3400  3.5494\n",
      " -6.0035  0.0641 -1.3876  ...   9.5362  4.3400  3.5494\n",
      "\n",
      "( 39 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -4.1483 -5.6160  9.6920  ...   7.3403  0.1617 -9.8408\n",
      " -9.2310  2.0112  7.0523  ...  -2.4429  9.5504 -8.1568\n",
      " -6.4610  6.8840 -4.4446  ...  -6.9465  9.6963  7.1842\n",
      "           ...             ⋱             ...          \n",
      " -6.0035  0.0641 -1.3876  ...   9.5362  4.3400  3.5494\n",
      " -6.0035  0.0641 -1.3876  ...   9.5362  4.3400  3.5494\n",
      " -6.0035  0.0641 -1.3876  ...   9.5362  4.3400  3.5494\n",
      "[torch.FloatTensor of size 40x4910x20]\n",
      "\n",
      "Variable containing:\n",
      " 0.6939\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "    0     0     0  ...      0     0     0\n",
      "    0     0     0  ...      0     0     0\n",
      "    0     0     0  ...      0     0     0\n",
      "       ...          ⋱          ...       \n",
      "    0     0     0  ...      0     0     0\n",
      "    0     0     0  ...      0     0     0\n",
      "    0     0     0  ...      0     0     0\n",
      "[torch.FloatTensor of size 963x20]\n",
      "\n",
      "\n",
      "   13    19     4  ...      0     0     0\n",
      "   13    19    13  ...      0     0     0\n",
      "   13    22    18  ...      0     0     0\n",
      "       ...          ⋱          ...       \n",
      "   13    19     5  ...      0     0     0\n",
      "   13    22    11  ...      0     0     0\n",
      "   13    22    17  ...      0     0     0\n",
      "[torch.DoubleTensor of size 963x4092]\n",
      "\n",
      "\n",
      "   13    19     4  ...      0     0     0\n",
      "   13    19    13  ...      0     0     0\n",
      "   13    22    18  ...      0     0     0\n",
      "       ...          ⋱          ...       \n",
      "   13    19     5  ...      0     0     0\n",
      "   13    22    11  ...      0     0     0\n",
      "   13    22    17  ...      0     0     0\n",
      "[torch.LongTensor of size 963x4092]\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "save_for_backward can only save input or output tensors, but argument 0 doesn't satisfy this condition",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-77dc93529de4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Model Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_test_LSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myeast_valid_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myeast_valid_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myeast_valid_lengths\u001b[0m\u001b[0;34m,\u001b[0m            \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mFScore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mThreshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPrecision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mRecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFScore_on_test_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myeast_test_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myeast_test_lengths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myeast_test_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-6f1e62b04811>\u001b[0m in \u001b[0;36mtrain_test_LSTM\u001b[0;34m(valid_sequences, valid_label, valid_length, num_epochs, optimizer, data_iter, model, training_length, lstm)\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                     \u001b[0mval_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mf_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Brenton/anaconda/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-d8858f6e0ff7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data, hidden, c, valid)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0membs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Brenton/anaconda/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Brenton/anaconda/lib/python3.5/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         )\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: save_for_backward can only save input or output tensors, but argument 0 doesn't satisfy this condition"
     ]
    }
   ],
   "source": [
    "data_size = len(yeast_train_sequences) #3447\n",
    "num_labels = yeast_GO_terms.shape[0] #26\n",
    "\n",
    "model = LSTM(vocab_size, emb_dim, hidden_size, num_labels, batch_size, validation_size, test_size)\n",
    "criterion = nn.MultiLabelSoftMarginLoss()  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "data_iter = batch_iter(yeast_train_vectors, yeast_train_labels, yeast_train_lengths, batch_size)\n",
    "\n",
    "# Model Training\n",
    "train_test_LSTM(yeast_valid_vectors, yeast_valid_labels, yeast_valid_lengths, \\\n",
    "           num_epochs, optimizer, data_iter, model, data_size, lstm=True)\n",
    "\n",
    "FScore,Threshold,Precision,Recall = FScore_on_test_set(model, yeast_test_vectors, yeast_test_lengths,yeast_test_labels, num_labels)\n",
    "\n",
    "# Prediction on test set\n",
    "print(\"Test Data F-Score for yeast protein prediction is\", FScore, '\\nTest Precision:',Precision,\n",
    "      '\\nTest Recall:',Recall, '\\nThreshold:', Threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
